{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOoyQ70H00_s"
   },
   "source": [
    "## Exercise 2\n",
    "In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "Some notes:\n",
    "1. It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\n",
    "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "\n",
    "I've started the code for you below -- how would you finish it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
    "# environment, then grab mnist.npz from the Coursera Jupyter Notebook\n",
    "# and place it inside a local folder and edit the path to that location\n",
    "path = f\"{getcwd()}/../tmp2/mnist.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                        \n",
    "        # YOUR CODE SHOULD START HERE\n",
    "            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=([callbacks])\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0308 04:59:52.487637 140554738845504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 2.3925 - acc: 0.8527\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.3635 - acc: 0.9100\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 277us/sample - loss: 0.2875 - acc: 0.9281\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.2501 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 275us/sample - loss: 0.2296 - acc: 0.9398\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 274us/sample - loss: 0.2184 - acc: 0.9449\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.2065 - acc: 0.9476\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.1971 - acc: 0.9515\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 277us/sample - loss: 0.1878 - acc: 0.9529\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.1890 - acc: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.95448333)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 264 neurons in the hidden layer\n",
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist1():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                        \n",
    "        # YOUR CODE SHOULD START HERE\n",
    "            tf.keras.layers.Dense(264, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=([callbacks])\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 281us/sample - loss: 2.4570 - acc: 0.8908\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.3193 - acc: 0.9295\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 0.2684 - acc: 0.9382\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 0.2532 - acc: 0.9419\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.2214 - acc: 0.9467\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.2155 - acc: 0.9502\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 0.1975 - acc: 0.9541\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.1980 - acc: 0.9542\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.1863 - acc: 0.9567\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 0.1846 - acc: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.95746666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 512 neurons in the hidden layer\n",
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist2():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                        \n",
    "        # YOUR CODE SHOULD START HERE\n",
    "            tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=([callbacks])\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 2.6770 - acc: 0.9058\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.3192 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 0.2985 - acc: 0.9409\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.2772 - acc: 0.9451\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 0.2521 - acc: 0.9494\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.2446 - acc: 0.9522\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.1969 - acc: 0.9582\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.2059 - acc: 0.9579\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.2023 - acc: 0.9596\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 0.1903 - acc: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.9622167)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 1024 neurons in the hidden layer. checking how many number of neurons to choose to get the callback effective and\n",
    "#and stopp at 99% of accuracy\n",
    "\n",
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist3():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                        \n",
    "        # YOUR CODE SHOULD START HERE\n",
    "            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=([callbacks])\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 2.5553 - acc: 0.9131\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 0.4113 - acc: 0.9378\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 0.3715 - acc: 0.9431\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 261us/sample - loss: 0.2920 - acc: 0.9487\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.3038 - acc: 0.9497\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 259us/sample - loss: 0.2617 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.2564 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.2394 - acc: 0.9606\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.2316 - acc: 0.9619\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 262us/sample - loss: 0.2110 - acc: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.9637167)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 2024 neurons in the hidden layer. checking how many number of neurons to choose to get the callback effective and\n",
    "#and stopp at 99% of accuracy\n",
    "\n",
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist4():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                        \n",
    "        # YOUR CODE SHOULD START HERE\n",
    "            tf.keras.layers.Dense(2024, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=([callbacks])\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 266us/sample - loss: 2.7840 - acc: 0.9165\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 0.5124 - acc: 0.9366\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 265us/sample - loss: 0.4500 - acc: 0.9428\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 264us/sample - loss: 0.3578 - acc: 0.9495\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 265us/sample - loss: 0.3300 - acc: 0.9541\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 265us/sample - loss: 0.2971 - acc: 0.9586\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 265us/sample - loss: 0.2830 - acc: 0.9586\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 265us/sample - loss: 0.2561 - acc: 0.9628\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.2615 - acc: 0.9617\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 264us/sample - loss: 0.2356 - acc: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.96578336)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 2024 neurons in the hidden layer. checking how many number of neurons to choose to get the callback effective and\n",
    "#and stopp at 99% of accuracy\n",
    "\n",
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist5():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                        \n",
    "        # YOUR CODE SHOULD START HERE\n",
    "            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=([callbacks])\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 297us/sample - loss: 1.2999 - acc: 0.9113\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 18s 297us/sample - loss: 0.1975 - acc: 0.9479\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s 292us/sample - loss: 0.1834 - acc: 0.9523\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.1595 - acc: 0.9595\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 297us/sample - loss: 0.1429 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.1241 - acc: 0.9688\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.1175 - acc: 0.9717\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.1036 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.0948 - acc: 0.9773\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 293us/sample - loss: 0.0913 - acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.97825)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 2024 neurons in the hidden layer. checking how many number of neurons to choose to get the callback effective and\n",
    "#and stopp at 99% of accuracy\n",
    "\n",
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist6():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                        \n",
    "        # YOUR CODE SHOULD START HERE\n",
    "            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=([callbacks])\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]\n",
    "\n",
    "\n",
    "#Observation:\n",
    "Increasing the number of neurons in the second hidden layer did not increase the accuracy compared to the fewer number of\n",
    "neurons in the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 293us/sample - loss: 1.4870 - acc: 0.9135\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.2097 - acc: 0.9481\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.1885 - acc: 0.9531\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.1698 - acc: 0.9585\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 292us/sample - loss: 0.1486 - acc: 0.9629\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.1197 - acc: 0.9695\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 294us/sample - loss: 0.1172 - acc: 0.9714\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.1054 - acc: 0.9761\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 292us/sample - loss: 0.1048 - acc: 0.9762\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.0953 - acc: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.97721666)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above.\n",
    "# Once that is complete, please run the following two cells to save your work and close the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Shutdown and close the notebook -->\n",
    "window.onbeforeunload = null\n",
    "window.close();\n",
    "IPython.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "introduction-tensorflow",
   "graded_item_id": "d6dew",
   "launcher_item_id": "FExZ4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
